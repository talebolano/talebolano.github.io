<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Tensorrt实现solov2加速</title>
      <link href="/2020/09/02/solo/"/>
      <url>/2020/09/02/solo/</url>
      
        <content type="html"><![CDATA[<p>solo系列网络是由Xinlong Wang提出的单阶段实例分割网络。其搭建在mmdetection库中。solov2主干网络如下图所示：</p><a id="more"></a>  <p><img src="/images/solobackbone.jpg" alt="faststyle1"></p><center>solov2实例分割网络</center> <p>Tensorrt实现solov2加速步骤如下所示：</p><p>1、修改solo中tensorrt或onnx不支持的层。solo原生代码中采用的group normalization层在onnx和tensorrt中支持性不高，会导致模型转换错误，因此将模型中所有group normalization层替换为batch normalization层。因为具体替换了模型的结构，因此还需对模型进行重新训练。</p><p><img src="/images/gn.jpg" alt="faststyle1"></p><center>onnx生成的gn层</center>![faststyle1](/images/upsample.jpg)<center>未指定缩放size情况下onnx生成的upsample层</center><p>2、进行pth模型到onnx模型的转换。pytorch1.3对应的onnx版本为1.6，其upsample层需具体转换尺寸，不然会在转tensorrt的过程中报错。此外，solo采用了较为特殊的coordconv，onnx不支持其采用的torch.linesapce操作，因此我们将coord中指明方向的两层保存为具体参数直接读取使用。转换onnx的具体代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import mmcv</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">from mmcv.runner import load_checkpoint</span><br><span class="line">from mmdet.models import build_detector</span><br><span class="line">import cv2</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from types import MethodType</span><br><span class="line">import torch.onnx as onnx</span><br><span class="line">from torchvision.transforms import Normalize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Norm(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Norm,self).__init__()</span><br><span class="line">        self.mean &#x3D; [0.485,0.456,0.406]</span><br><span class="line">        self.std &#x3D; [0.229,0.224,0.225]</span><br><span class="line">        self.normal &#x3D; Normalize(self.mean,self.std)</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x &#x3D; x.squeeze(0)</span><br><span class="line">        x &#x3D; x&#x2F;255.</span><br><span class="line">        return self.normal(x).unsqueeze(0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def points_nms(heat,kernel&#x3D;2):</span><br><span class="line">    hmax &#x3D; F.max_pool2d(</span><br><span class="line">        heat,(kernel,kernel),stride&#x3D;1,padding&#x3D;1</span><br><span class="line">    )</span><br><span class="line">    keep &#x3D; (hmax[:,:,:-1,:-1] &#x3D;&#x3D; heat).float()</span><br><span class="line">    return heat*keep</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def fpn_forward(self,inputs):</span><br><span class="line">    assert len(inputs)&#x3D;&#x3D;len(self.in_channels)</span><br><span class="line">    laterals &#x3D; [</span><br><span class="line">        lateral_conv(inputs[i+self.start_level])</span><br><span class="line">        for i,lateral_conv in self.lateral_convs</span><br><span class="line">    ]</span><br><span class="line">    used_backbone_levels &#x3D; len(laterals)</span><br><span class="line">    for i in range(used_backbone_levels-1,0,-1):</span><br><span class="line">        sh &#x3D; torch.tensor(laterals[i].shape)</span><br><span class="line">        laterals[i-1] +&#x3D; F.interpolate(</span><br><span class="line">            laterals[i],size&#x3D;(sh[2]*2,sh[3]*2),mode&#x3D;&quot;nearest&quot;</span><br><span class="line">        )</span><br><span class="line">    outs &#x3D; [</span><br><span class="line">        self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    if self.num_outs&gt;len(outs):</span><br><span class="line">        if not self.add_extra_convs:</span><br><span class="line">            for i in range(self.num_outs-used_backbone_levels):</span><br><span class="line">                outs.append(F.max_pool2d(outs[-1],1,stride&#x3D;2))</span><br><span class="line">        else:</span><br><span class="line">            if self.extra_convs_on_inputs:</span><br><span class="line">                orig &#x3D; inputs[self.backbone_end_level -1]</span><br><span class="line">                outs.append(self.fpn_convs[used_backbone_levels](orig))</span><br><span class="line">            else:</span><br><span class="line">                outs.append(self.fpn_convs[used_backbone_levels](outs[-1]))</span><br><span class="line">            for i in range(used_backbone_levels + 1,self.num_outs):</span><br><span class="line">                if self.relu_before_extra_convs:</span><br><span class="line">                    outs.append(self.fpn_convs[i](F.relu(outs[-1])))</span><br><span class="line">                else:</span><br><span class="line">                    outs.append(self.fpn_convs[i](outs[-1]))</span><br><span class="line">    return tuple(outs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def forward_single(self, x, idx, eval&#x3D;False, upsampled_size&#x3D;None):</span><br><span class="line">    ins_kernel_feat &#x3D; x</span><br><span class="line">    coord_feat &#x3D; self.coord[idx]</span><br><span class="line">    seg_num_grid &#x3D; self.seg_num_grids[idx]</span><br><span class="line">    cate_feat &#x3D; F.interpolate(ins_kernel_feat,size&#x3D;seg_num_grid,mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line"></span><br><span class="line">    kernel_feat &#x3D; torch.cat([ins_kernel_feat,coord_feat],1)</span><br><span class="line"></span><br><span class="line">    kernel_feat &#x3D; F.interpolate(kernel_feat, size&#x3D;seg_num_grid, mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line"></span><br><span class="line">    kernel_feat &#x3D; kernel_feat.contiguous()</span><br><span class="line">    for i, kernel_layer in enumerate(self.kernel_convs):</span><br><span class="line">        kernel_feat &#x3D; kernel_layer(kernel_feat)</span><br><span class="line">    kernel_pred &#x3D; self.solo_kernel(kernel_feat)  # 256</span><br><span class="line"></span><br><span class="line">    # cate branch</span><br><span class="line">    cate_feat &#x3D; cate_feat.contiguous()</span><br><span class="line">    for i, cate_layer in enumerate(self.cate_convs):</span><br><span class="line">        cate_feat &#x3D; cate_layer(cate_feat)</span><br><span class="line">    cate_pred &#x3D; self.solo_cate(cate_feat)  # B*S*S*80</span><br><span class="line"></span><br><span class="line">    if eval:</span><br><span class="line">        cate_pred &#x3D; points_nms(cate_pred.sigmoid(), kernel&#x3D;2).permute(0, 2, 3, 1)</span><br><span class="line">    return cate_pred, kernel_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def split_feats(self, feats):</span><br><span class="line">    sh1 &#x3D; torch.tensor(feats[0].shape)</span><br><span class="line">    sh2 &#x3D; torch.tensor(feats[3].shape)</span><br><span class="line">    return (F.interpolate(feats[0], size&#x3D;(int(sh1[2]*0.5),int(sh1[3]*0.5)), mode&#x3D;&#39;bilinear&#39;),</span><br><span class="line">            feats[1],</span><br><span class="line">            feats[2],</span><br><span class="line">            feats[3],</span><br><span class="line">            F.interpolate(feats[4], size&#x3D;(sh2[2],sh1[3]), mode&#x3D;&#39;bilinear&#39;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def forward(self, inputs):</span><br><span class="line">    assert len(inputs) &#x3D;&#x3D; (self.end_level - self.start_level + 1)</span><br><span class="line"></span><br><span class="line">    feature_add_all_level &#x3D; self.convs_all_levels[0](inputs[0])</span><br><span class="line">    x &#x3D; self.convs_all_levels[1].conv0(inputs[1])</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    feature_add_all_level +&#x3D; F.interpolate(x,size&#x3D;(sh[2]*2,sh[3]*2),mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line"></span><br><span class="line">    x &#x3D; self.convs_all_levels[2].conv0(inputs[2])</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    x &#x3D; F.interpolate(x,size&#x3D;(sh[2]*2,sh[3]*2),mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line">    x &#x3D; self.convs_all_levels[2].conv1(x)</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    feature_add_all_level +&#x3D; F.interpolate(x,size&#x3D;(sh[2]*2,sh[3]*2),mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line"></span><br><span class="line">    coord_feat &#x3D; self.coord</span><br><span class="line">    input_p &#x3D; torch.cat([inputs[3],coord_feat],1)</span><br><span class="line">    x &#x3D; self.convs_all_levels[3].conv0(input_p)</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    x &#x3D; F.interpolate(x, size&#x3D;(sh[2] * 2, sh[3] * 2), mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line">    x &#x3D; self.convs_all_levels[3].conv1(x)</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    x &#x3D; F.interpolate(x, size&#x3D;(sh[2] * 2, sh[3] * 2), mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line">    x &#x3D; self.convs_all_levels[3].conv2(x)</span><br><span class="line">    sh &#x3D; torch.tensor(x.shape)</span><br><span class="line">    feature_add_all_level +&#x3D; F.interpolate(x, size&#x3D;(sh[2] * 2, sh[3] * 2), mode&#x3D;&quot;bilinear&quot;)</span><br><span class="line"></span><br><span class="line">    feature_pred &#x3D; self.conv_pred(feature_add_all_level)</span><br><span class="line">    return feature_pred</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main_forward(self,img):</span><br><span class="line">    x &#x3D; self.normal(img)</span><br><span class="line">    x &#x3D; self.extract_feat(x)</span><br><span class="line">    outs &#x3D; self.bbox_head(x)</span><br><span class="line">    mask_feat_pred &#x3D; self.mask_feat_head(</span><br><span class="line">        x[self.mask_feat_head.start_level:self.mask_feat_head.end_level + 1]</span><br><span class="line">    )</span><br><span class="line">    cate_class &#x3D; int(outs[0][0].shape[-1])</span><br><span class="line">    cate_pred_list &#x3D; [</span><br><span class="line">        outs[0][i].view(-1,cate_class) for i in range(5)</span><br><span class="line">    ]</span><br><span class="line">    kernel_shape &#x3D; int(outs[1][0].shape[1])</span><br><span class="line">    kernel_pred_list &#x3D; [</span><br><span class="line">        outs[1][i].squeeze(0).permute(1,2,0).view(-1,kernel_shape) for i in range(5)</span><br><span class="line">    ]</span><br><span class="line">    cate_pred_list &#x3D; torch.cat(cate_pred_list,dim&#x3D;0)</span><br><span class="line">    kernel_pred_list &#x3D; torch.cat(kernel_pred_list, dim&#x3D;0)</span><br><span class="line"></span><br><span class="line">    return (cate_pred_list,kernel_pred_list,mask_feat_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_args():</span><br><span class="line">    parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;MMDet onnx model&#39;)</span><br><span class="line">    parser.add_argument(&#39;config&#39;, help&#x3D;&#39;test config file path&#39;)</span><br><span class="line">    parser.add_argument(&#39;checkpoint&#39;, help&#x3D;&#39;checkpoint file&#39;)</span><br><span class="line">    parser.add_argument(&#39;output&#39;,help&#x3D;&#39;output onnx file&#39;)</span><br><span class="line">    args &#x3D; parser.parse_args()</span><br><span class="line">    return args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    args &#x3D; parse_args()</span><br><span class="line"></span><br><span class="line">    cfg &#x3D; mmcv.Config.fromfile(args.config)</span><br><span class="line">    cfg.model.pretrained &#x3D; None</span><br><span class="line">    cfg.data.test.test_mode &#x3D; True</span><br><span class="line"></span><br><span class="line">    # build the model and load checkpoint</span><br><span class="line">    model &#x3D; build_detector(cfg.model, train_cfg&#x3D;None, test_cfg&#x3D;cfg.test_cfg)</span><br><span class="line">    x &#x3D; [torch.load(&quot;coord1.pth&quot;),torch.load(&quot;coord2.pth&quot;),</span><br><span class="line">         torch.load(&quot;coord3.pth&quot;),torch.load(&quot;coord4.pth&quot;),</span><br><span class="line">         torch.load(&quot;coord5.pth&quot;)]</span><br><span class="line">    model.bbox_head.coord &#x3D; x</span><br><span class="line">    model.bbox_head.forward_single &#x3D; MethodType(forward_single,model.bbox_head)</span><br><span class="line">    model.bbox_head.split_feats &#x3D; MethodType(split_feats, model.bbox_head)</span><br><span class="line">    model.mask_feat_head.coord&#x3D;x[-1]</span><br><span class="line">    model.mask_feat_head.forward &#x3D; MethodType(forward,model.mask_feat_head)</span><br><span class="line">    model.neck.forward &#x3D; MethodType(fpn_forward,model.neck)</span><br><span class="line"></span><br><span class="line">    model.normal &#x3D; Norm()</span><br><span class="line">    model.forward &#x3D; MethodType(main_forward,model)</span><br><span class="line"></span><br><span class="line">    img &#x3D; torch.randn(1,3,800,1344)</span><br><span class="line"></span><br><span class="line">    checkpoint &#x3D; load_checkpoint(model,args.checkpoint,map_location&#x3D;&#39;cpu&#39;)</span><br><span class="line">    onnx.export(model,img,args.output,verbose&#x3D;True,opset_version&#x3D;10)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>3、进行onnx模型到tensorrt模型的转换。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br></pre></td><td class="code"><pre><span class="line">import pycuda.driver as cuda</span><br><span class="line">import pycuda.autoinit</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import tensorrt as trt</span><br><span class="line">import time</span><br><span class="line">import argparse</span><br><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">seg_num_grids &#x3D; [40,36,24,16,12]</span><br><span class="line">self_strides &#x3D; [8,8,16,32,32]</span><br><span class="line">score_thr &#x3D; 0.1</span><br><span class="line">mask_thr &#x3D; 0.5</span><br><span class="line">max_per_img &#x3D; 100</span><br><span class="line">class_names &#x3D; [] # 输入你模型要预测类的名字</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class HostDeviceMem(object):</span><br><span class="line">    def __init__(self, host_mem, device_mem):</span><br><span class="line">        self.host &#x3D; host_mem</span><br><span class="line">        self.device &#x3D; device_mem</span><br><span class="line"></span><br><span class="line">    def __str__(self):</span><br><span class="line">        return &quot;Host:\n&quot; + str(self.host) + &quot;\nDevice:\n&quot; + str(self.device)</span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        return self.__str__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Preprocessimage(object):</span><br><span class="line">    def __init__(self,inszie):</span><br><span class="line">        self.inszie &#x3D; inszie</span><br><span class="line"></span><br><span class="line">    def process(self,image_path):</span><br><span class="line">        start &#x3D; time.time()</span><br><span class="line">        image &#x3D; cv2.imread(image_path) # bgr rgb</span><br><span class="line">        image &#x3D; cv2.cvtColor(image,cv2.COLOR_BGR2RGB)</span><br><span class="line">        H,W,_ &#x3D; image.shape</span><br><span class="line"></span><br><span class="line">        img_metas &#x3D; dict()</span><br><span class="line">        image &#x3D; cv2.resize(image,self.inszie) # resize</span><br><span class="line">        img_metas[&quot;img_shape&quot;] &#x3D; image.shape</span><br><span class="line">        image_raw &#x3D; cv2.cvtColor(image,cv2.COLOR_RGB2BGR)</span><br><span class="line"></span><br><span class="line">        image &#x3D; image.transpose([2,0,1]) # chw</span><br><span class="line">        image &#x3D; np.expand_dims(image,axis&#x3D;0) # nchw</span><br><span class="line">        image &#x3D; np.array(image,dtype&#x3D;np.float32,order&#x3D;&quot;C&quot;)</span><br><span class="line">        print(&quot;preprocess time &#123;:.3f&#125; ms&quot;.format((time.time()-start)*1000))</span><br><span class="line">        return image,image_raw,img_metas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_engine(onnx_path,engine_path,TRT_LOGGER,mode&#x3D;&quot;fp16&quot;):</span><br><span class="line">    # 如果有engine直接用，否则构建新的engine</span><br><span class="line">    def build_engine():</span><br><span class="line">        EXPLICIT_BATCH &#x3D; 1&lt;&lt;(int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)</span><br><span class="line">        with trt.Builder(TRT_LOGGER) as builder,\</span><br><span class="line">            builder.create_network(EXPLICIT_BATCH) as network,\</span><br><span class="line">            trt.OnnxParser(network,TRT_LOGGER) as parser:</span><br><span class="line">            builder.max_workspace_size &#x3D; 1&lt;&lt;30</span><br><span class="line">            builder.max_batch_size &#x3D; 1</span><br><span class="line">            if mode&#x3D;&#x3D;&quot;fp16&quot;:</span><br><span class="line">                builder.fp16_mode &#x3D; True</span><br><span class="line">            if not os.path.exists(onnx_path):</span><br><span class="line">                print(&quot;onnx file &#123;&#125; not found&quot;.format(onnx_path))</span><br><span class="line">                exit(0)</span><br><span class="line">            print(&quot;loading onnx file &#123;&#125; .....&quot;.format(onnx_path))</span><br><span class="line">            with open(onnx_path,&#39;rb&#39;) as model:</span><br><span class="line">                print(&quot;Begining parsing....&quot;)</span><br><span class="line">                parser.parse(model.read())</span><br><span class="line">            print(&quot;completed parsing&quot;)</span><br><span class="line">            print(&quot;Building an engine from file &#123;&#125;&quot;.format(onnx_path))</span><br><span class="line">            network.get_input(0).shape &#x3D; [1,3,800,1344]</span><br><span class="line">            engine &#x3D; builder.build_cuda_engine(network)</span><br><span class="line"></span><br><span class="line">            print(&quot;completed build engine&quot;)</span><br><span class="line">            with open(engine_path,&quot;wb&quot;) as f:</span><br><span class="line">                f.write(engine.serialize())</span><br><span class="line">            return engine</span><br><span class="line">    if os.path.exists(engine_path):</span><br><span class="line">        print(&quot;loading engine file &#123;&#125; ...&quot;.format(engine_path))</span><br><span class="line">        with open(engine_path,&quot;rb&quot;) as f,\</span><br><span class="line">            trt.Runtime(TRT_LOGGER) as runtime:</span><br><span class="line">            return runtime.deserialize_cuda_engine(f.read())</span><br><span class="line">    else:</span><br><span class="line">        return build_engine()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def allocate_buffers(engine):</span><br><span class="line">    inputs &#x3D; []</span><br><span class="line">    outputs &#x3D; []</span><br><span class="line">    bindings &#x3D; []</span><br><span class="line">    stream &#x3D; cuda.Stream()</span><br><span class="line"></span><br><span class="line">    for binding in engine:</span><br><span class="line">        size &#x3D; trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size</span><br><span class="line">        dtype &#x3D; trt.nptype(engine.get_binding_dtype(binding))</span><br><span class="line">        host_mem &#x3D; cuda.pagelocked_empty(size,dtype)</span><br><span class="line">        device_mem &#x3D; cuda.mem_alloc(host_mem.nbytes)</span><br><span class="line"></span><br><span class="line">        bindings.append(int(device_mem))</span><br><span class="line"></span><br><span class="line">        if engine.binding_is_input(binding):</span><br><span class="line">            inputs.append(HostDeviceMem(host_mem,device_mem))</span><br><span class="line">        else:</span><br><span class="line">            outputs.append(HostDeviceMem(host_mem,device_mem))</span><br><span class="line"></span><br><span class="line">    return inputs,outputs,bindings,stream</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def do_inference(context,bindings,inputs,outputs,stream,batch_size&#x3D;1):</span><br><span class="line">    [cuda.memcpy_htod_async(inp.device,inp.host,stream) for inp in inputs]</span><br><span class="line"></span><br><span class="line">    context.execute_async_v2(bindings&#x3D;bindings,stream_handle&#x3D;stream.handle)</span><br><span class="line"></span><br><span class="line">    [cuda.memcpy_dtoh_async(out.host,out.device,stream) for out in outputs]</span><br><span class="line"></span><br><span class="line">    stream.synchronize()</span><br><span class="line"></span><br><span class="line">    return [out.host for out in outputs]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def matrix_nms(seg_masks, cate_labels, cate_scores, kernel&#x3D;&#39;gaussian&#39;, sigma&#x3D;2.0, sum_masks&#x3D;None):</span><br><span class="line">    &quot;&quot;&quot;Matrix NMS for multi-class masks.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        seg_masks (Tensor): shape (n, h, w)</span><br><span class="line">        cate_labels (Tensor): shape (n), mask labels in descending order</span><br><span class="line">        cate_scores (Tensor): shape (n), mask scores in descending order</span><br><span class="line">        kernel (str):  &#39;linear&#39; or &#39;gauss&#39;</span><br><span class="line">        sigma (float): std in gaussian method</span><br><span class="line">        sum_masks (Tensor): The sum of seg_masks</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">        Tensor: cate_scores_update, tensors of shape (n)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    n_samples &#x3D; len(cate_labels)</span><br><span class="line">    if n_samples &#x3D;&#x3D; 0:</span><br><span class="line">        return []</span><br><span class="line">    if sum_masks is None:</span><br><span class="line">        sum_masks &#x3D; seg_masks.sum((1, 2)).float()</span><br><span class="line">    seg_masks &#x3D; seg_masks.reshape(n_samples, -1).float()</span><br><span class="line">    # inter.</span><br><span class="line">    inter_matrix &#x3D; torch.mm(seg_masks, seg_masks.transpose(1, 0))</span><br><span class="line">    # union.</span><br><span class="line">    sum_masks_x &#x3D; sum_masks.expand(n_samples, n_samples)</span><br><span class="line">    # iou.</span><br><span class="line">    iou_matrix &#x3D; (inter_matrix &#x2F; (sum_masks_x + sum_masks_x.transpose(1, 0) - inter_matrix)).triu(diagonal&#x3D;1)</span><br><span class="line">    # label_specific matrix.</span><br><span class="line">    cate_labels_x &#x3D; cate_labels.expand(n_samples, n_samples)</span><br><span class="line">    label_matrix &#x3D; (cate_labels_x &#x3D;&#x3D; cate_labels_x.transpose(1, 0)).float().triu(diagonal&#x3D;1)</span><br><span class="line"></span><br><span class="line">    # IoU compensation</span><br><span class="line">    compensate_iou, _ &#x3D; (iou_matrix * label_matrix).max(0)</span><br><span class="line">    compensate_iou &#x3D; compensate_iou.expand(n_samples, n_samples).transpose(1, 0)</span><br><span class="line"></span><br><span class="line">    # IoU decay</span><br><span class="line">    decay_iou &#x3D; iou_matrix * label_matrix</span><br><span class="line"></span><br><span class="line">    # matrix nms</span><br><span class="line">    if kernel &#x3D;&#x3D; &#39;gaussian&#39;:</span><br><span class="line">        decay_matrix &#x3D; torch.exp(-1 * sigma * (decay_iou ** 2))</span><br><span class="line">        compensate_matrix &#x3D; torch.exp(-1 * sigma * (compensate_iou ** 2))</span><br><span class="line">        decay_coefficient, _ &#x3D; (decay_matrix &#x2F; compensate_matrix).min(0)</span><br><span class="line">    elif kernel &#x3D;&#x3D; &#39;linear&#39;:</span><br><span class="line">        decay_matrix &#x3D; (1-decay_iou)&#x2F;(1-compensate_iou)</span><br><span class="line">        decay_coefficient, _ &#x3D; decay_matrix.min(0)</span><br><span class="line">    else:</span><br><span class="line">        raise NotImplementedError</span><br><span class="line"></span><br><span class="line">    # update the score.</span><br><span class="line">    cate_scores_update &#x3D; cate_scores * decay_coefficient</span><br><span class="line">    return cate_scores_update</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_seg_single(cate_preds,</span><br><span class="line">                seg_preds,</span><br><span class="line">                kernel_preds,</span><br><span class="line">                img_metas):</span><br><span class="line"></span><br><span class="line">    img_shape &#x3D; img_metas[&#39;img_shape&#39;]</span><br><span class="line"></span><br><span class="line">    # overall info.</span><br><span class="line">    h, w, _ &#x3D; img_shape</span><br><span class="line"></span><br><span class="line">    featmap_size &#x3D; seg_preds.size()[-2:]</span><br><span class="line">    upsampled_size_out &#x3D; (featmap_size[0] * 4, featmap_size[1] * 4) #seg # 1344,800</span><br><span class="line"></span><br><span class="line">    # process.</span><br><span class="line">    inds &#x3D; (cate_preds &gt; score_thr)</span><br><span class="line">    cate_scores &#x3D; cate_preds[inds]</span><br><span class="line">    if len(cate_scores) &#x3D;&#x3D; 0:</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line">    # cate_labels &amp; kernel_preds</span><br><span class="line">    inds &#x3D; inds.nonzero()</span><br><span class="line">    cate_labels &#x3D; inds[:, 1]</span><br><span class="line">    kernel_preds &#x3D; kernel_preds[inds[:, 0]] # 选择cate大于阈值对应的kernel</span><br><span class="line"></span><br><span class="line">    # trans vector.</span><br><span class="line">    size_trans &#x3D; cate_labels.new_tensor(seg_num_grids).pow(2).cumsum(0) # tensor([1600, 2896, 3472, 3728, 3872])</span><br><span class="line">    strides &#x3D; kernel_preds.new_ones(size_trans[-1]) #  [1,1,1,1,....,1] # 3872 所有的s*s累加</span><br><span class="line"></span><br><span class="line">    n_stage &#x3D; len(seg_num_grids) # 5</span><br><span class="line">    strides[:size_trans[0]] *&#x3D; self_strides[0] # [8,8,8,8......,8] 前1600乘8</span><br><span class="line">    for ind_ in range(1, n_stage): #2,3,4,5</span><br><span class="line">        strides[size_trans[ind_-1]:size_trans[ind_]] *&#x3D; self_strides[ind_] # self.strides[8, 8, 16, 32, 32]</span><br><span class="line">    strides &#x3D; strides[inds[:, 0]] # 选择前坐标</span><br><span class="line"></span><br><span class="line">    # mask encoding.</span><br><span class="line">    I, N &#x3D; kernel_preds.shape #( 选出的kernel,256)</span><br><span class="line">    kernel_preds &#x3D; kernel_preds.view(I, N, 1, 1) # (out_channels，in_channe&#x2F;groups，H，W)</span><br><span class="line">    seg_preds &#x3D; F.conv2d(seg_preds, kernel_preds, stride&#x3D;1).squeeze(0).sigmoid() #(选出的kernel,h,w)</span><br><span class="line">    # mask.</span><br><span class="line">    seg_masks &#x3D; seg_preds &gt; mask_thr</span><br><span class="line">    sum_masks &#x3D; seg_masks.sum((1, 2)).float()</span><br><span class="line"></span><br><span class="line">    # filter.</span><br><span class="line">    keep &#x3D; sum_masks &gt; strides # 大于相对应的stride</span><br><span class="line">    if keep.sum() &#x3D;&#x3D; 0:</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line">    seg_masks &#x3D; seg_masks[keep, ...]</span><br><span class="line">    seg_preds &#x3D; seg_preds[keep, ...]</span><br><span class="line">    sum_masks &#x3D; sum_masks[keep]</span><br><span class="line">    cate_scores &#x3D; cate_scores[keep]</span><br><span class="line">    cate_labels &#x3D; cate_labels[keep]</span><br><span class="line"></span><br><span class="line">    # mask scoring.</span><br><span class="line">    seg_scores &#x3D; (seg_preds * seg_masks.float()).sum((1, 2)) &#x2F; sum_masks</span><br><span class="line">    cate_scores *&#x3D; seg_scores</span><br><span class="line"></span><br><span class="line">    # sort and keep top nms_pre</span><br><span class="line">    sort_inds &#x3D; torch.argsort(cate_scores, descending&#x3D;True)</span><br><span class="line">    if len(sort_inds) &gt; max_per_img:</span><br><span class="line">        sort_inds &#x3D; sort_inds[:max_per_img]</span><br><span class="line">    seg_masks &#x3D; seg_masks[sort_inds, :, :]</span><br><span class="line">    seg_preds &#x3D; seg_preds[sort_inds, :, :]</span><br><span class="line">    sum_masks &#x3D; sum_masks[sort_inds]</span><br><span class="line">    cate_scores &#x3D; cate_scores[sort_inds]</span><br><span class="line">    cate_labels &#x3D; cate_labels[sort_inds]</span><br><span class="line"></span><br><span class="line">    # Matrix NMS</span><br><span class="line">    cate_scores &#x3D; matrix_nms(seg_masks, cate_labels, cate_scores,</span><br><span class="line">                                    kernel&#x3D;&#39;gaussian&#39;,sigma&#x3D;2., sum_masks&#x3D;sum_masks)</span><br><span class="line"></span><br><span class="line">    seg_preds &#x3D; cv2.resize(seg_preds.permute(1,2,0).numpy(),</span><br><span class="line">                           (upsampled_size_out[1],upsampled_size_out[0])).transpose(2,0,1)</span><br><span class="line"></span><br><span class="line">    seg_masks &#x3D; seg_masks &gt; mask_thr</span><br><span class="line">    return seg_masks, cate_labels, cate_scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def vis_seg(image_raw,result,score_thresh,output):</span><br><span class="line">    img_show &#x3D; image_raw</span><br><span class="line">    seg_label &#x3D; result[0]</span><br><span class="line">    seg_label &#x3D; seg_label.astype(np.uint8)</span><br><span class="line">    cate_label &#x3D; result[1]</span><br><span class="line">    cate_label &#x3D; cate_label.numpy()</span><br><span class="line">    score &#x3D; result[2].numpy()</span><br><span class="line"></span><br><span class="line">    vis_inds &#x3D; score &gt; score_thresh</span><br><span class="line">    seg_label &#x3D; seg_label[vis_inds]</span><br><span class="line">    num_mask &#x3D; seg_label.shape[0]</span><br><span class="line">    cate_label &#x3D; cate_label[vis_inds]</span><br><span class="line">    cate_score &#x3D; score[vis_inds]</span><br><span class="line"></span><br><span class="line">    mask_density &#x3D; []</span><br><span class="line">    for idx in range(num_mask):</span><br><span class="line">        cur_mask &#x3D; seg_label[idx, :, :]</span><br><span class="line"></span><br><span class="line">        mask_density.append(cur_mask.sum())</span><br><span class="line">    orders &#x3D; np.argsort(mask_density)</span><br><span class="line">    seg_label &#x3D; seg_label[orders]</span><br><span class="line">    cate_label &#x3D; cate_label[orders]</span><br><span class="line">    cate_score &#x3D; cate_score[orders]</span><br><span class="line"></span><br><span class="line">    seg_show &#x3D; img_show.copy()</span><br><span class="line">    for idx in range(num_mask):</span><br><span class="line">        idx &#x3D; -(idx + 1)</span><br><span class="line">        cur_mask &#x3D; seg_label[idx, :, :]</span><br><span class="line"></span><br><span class="line">        if cur_mask.sum() &#x3D;&#x3D; 0:</span><br><span class="line">            continue</span><br><span class="line">        color_mask &#x3D; (np.random.randint(0,255),np.random.randint(0,255),np.random.randint(0,255))</span><br><span class="line">        contours,_ &#x3D; cv2.findContours(cur_mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)</span><br><span class="line">        cv2.drawContours(seg_show,contours,-1,color_mask,-1)</span><br><span class="line">        cur_cate &#x3D; cate_label[idx]</span><br><span class="line">        label_text &#x3D; class_names[cur_cate]</span><br><span class="line">        x1,y1,w,h &#x3D; cv2.boundingRect(cur_mask)</span><br><span class="line">        x2 &#x3D; x1+w</span><br><span class="line">        y2 &#x3D; y1+h</span><br><span class="line">        vis_pos &#x3D; (max(int(x1)-10,0),int(y1))</span><br><span class="line">        cv2.rectangle(seg_show,(x1,y1),(x2,y2),(0,0,0),thickness&#x3D;2)</span><br><span class="line">        cv2.putText(seg_show,label_text,vis_pos,cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0))</span><br><span class="line">        seg_show1 &#x3D; cv2.addWeighted(seg_show,0.7,img_show,0.5,0)</span><br><span class="line">    cv2.imwrite(output,seg_show1)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">def main():</span><br><span class="line"></span><br><span class="line">    args &#x3D; argparse.ArgumentParser(description&#x3D;&quot;trt pose predict&quot;)</span><br><span class="line">    args.add_argument(&quot;--onnx_path&quot;,type&#x3D;str,default&#x3D;&quot;dense121.onnx&quot;)</span><br><span class="line">    args.add_argument(&quot;--engine_path&quot;,type&#x3D;str,default&#x3D;&quot;dense121fp16.trt&quot;)</span><br><span class="line">    args.add_argument(&quot;--image_path&quot;,type&#x3D;str)</span><br><span class="line">    args.add_argument(&quot;--mode&quot;,type&#x3D;str,default&#x3D;&quot;fp16&quot;)</span><br><span class="line">    args.add_argument(&quot;--output&quot;,type&#x3D;str,default&#x3D;&quot;result.png&quot;)</span><br><span class="line">    opt &#x3D; args.parse_args()</span><br><span class="line"></span><br><span class="line">    insize &#x3D; (1344,800)</span><br><span class="line"></span><br><span class="line">    output_shape &#x3D; [(1, 256, 200, 336),(3872,6),(3872,256)]</span><br><span class="line">    TRT_LOGGER &#x3D; trt.Logger()</span><br><span class="line">    preprocesser &#x3D; Preprocessimage(insize)</span><br><span class="line"></span><br><span class="line">    image, image_raw,img_metas &#x3D; preprocesser.process(opt.image_path)</span><br><span class="line"></span><br><span class="line">    with get_engine(opt.onnx_path,opt.engine_path,TRT_LOGGER,opt.mode) as engine, \</span><br><span class="line">        engine.create_execution_context() as context:</span><br><span class="line">        inputs,outputs,bindings,stream &#x3D; allocate_buffers(engine)</span><br><span class="line"></span><br><span class="line">        inputs[0].host &#x3D; image</span><br><span class="line">        start &#x3D; time.time()</span><br><span class="line">        trt_outputs &#x3D; do_inference(context,bindings,inputs,outputs,stream)</span><br><span class="line">        end &#x3D; time.time()</span><br><span class="line">        print(&quot;inference time &#123;:.3f&#125; ms&quot;.format((end-start)*1000))</span><br><span class="line">    trt_outputs &#x3D; [output.reshape(shape) for output ,shape in zip(trt_outputs,output_shape)]</span><br><span class="line">    trt_outputs &#x3D; [torch.tensor(output) for output in trt_outputs]</span><br><span class="line"></span><br><span class="line">    cate_pred &#x3D; trt_outputs[1]</span><br><span class="line">    kernel_pred &#x3D; trt_outputs[2]</span><br><span class="line">    seg_pred &#x3D; trt_outputs[0]</span><br><span class="line">    </span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        result &#x3D; get_seg_single(cate_pred,kernel_pred,seg_pred,img_metas)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__&#x3D;&#x3D;&quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>九里</title>
      <link href="/2020/04/28/my-poem-2/"/>
      <url>/2020/04/28/my-poem-2/</url>
      
        <content type="html"><![CDATA[<h1 id="九里（2017-2020）"><a href="#九里（2017-2020）" class="headerlink" title="九里（2017-2020）"></a>九里（2017-2020）</h1><h3 id="建构"><a href="#建构" class="headerlink" title="建构"></a>建构</h3><p>失败了……却还在继续<br>叹息浮在房间<br>光线里，它们沉积着<br>饮水机反复发热、<br>人们起身坐下的频率  </p><p>她的脑中落满耳鸣<br>液态的下午缓缓降下<br>犹如水滴、细语的化石<br>落日时刻碎裂成图画<br>这易朽的一帧，赐予延时的平静  </p><p align="right">2017-9<p>  <a id="more"></a>   <h3 id="冷暴力"><a href="#冷暴力" class="headerlink" title="冷暴力"></a>冷暴力</h3><p>下潜的钟摆，公寓斜入傍晚<br>晚宴搅动胶稠的肢体。 </p><p>消失已久的人，聚敛于雾和谜语<br>沉默于嬉戏。单向的话语<br>触抵锁骨，述说又述说<br>无力复制着暴力的甜度。  </p><p>退潮时刻，她睁开眼慢慢<br>抚慰波浪。一颗海水之柚<br>笑容在海岸线上消散  </p><p>颠倒的回忆在偷窥，永远置身别处<br>此刻转身又返回舞池的她<br>她的星星，她，而她……  </p><p align="right">2018-12<p>  <h3 id="夏日"><a href="#夏日" class="headerlink" title="夏日"></a>夏日</h3><p>从一次坠落开始，下午<br>松弛它弹性的引力  </p><p>时钟的结构，损毁于沙砾<br>时间替代而非修复  </p><p>抵达尚未开始，夏日之舟<br>从一次跳跃等待下一次  </p><p>当它游弋，静止在洗碗池中<br>黄昏暴晒下一颗秋果  </p><p>扰动的果蝇，盘绕腐败的瘿心<br>声音，疲倦只是本旧书  </p><p align="right">2019-8<p><h3 id="青年路"><a href="#青年路" class="headerlink" title="青年路"></a>青年路</h3><p>深冬，老人们一涌而上<br>空置的膀胱顿时拥挤、发涨<br>热气从沙漏中倾斜出<br>新衣服，旧书包  </p><p>陌生的新生、说笑着沉没<br>习作在校门口步入拘谨<br>她或忆起:没有读完的旧书，电光葡萄<br>和一个修正主义的休止符……  </p><p>积雪使人老，虚构一个人<br>就是偷窥他一生所有的痛苦<br>练习青铜中舔食沙砾和盐<br>她已接受，雨水突然哑火的快乐  </p><p align="right">2019-10<p><h3 id="回忆之冬"><a href="#回忆之冬" class="headerlink" title="回忆之冬"></a>回忆之冬</h3><p>&emsp;&emsp;——忆与王尧等友同游泰山  </p><p>从中天门向下，山体的一半<br>穿过林地腐烂、膨大，抵达<br>坚实的柏油路。<br>几个小时的雨已让他们衣服湿透<br>现在，一天最冷的时刻，三人下山<br>放弃渺茫的日出<br>滚落盘山公路，旋转的逃生出口  </p><p>之后的事大抵类似<br>游学从此刻开始，生活之树<br>坠入雾与嬉戏，习作止步<br>舔食技术和暴力。<br>夜晚浮现它注定的谜语<br>如果诗歌失败了，<br>那生活为什么要成功？  </p><p align="right">2019-10<p><h3 id="夜会"><a href="#夜会" class="headerlink" title="夜会"></a>夜会</h3><p>又是一个夜晚，我们坐着<br>一些声音消失了，另一些<br>就会自动涌上桌来，填补<br>突然沉默的缝隙。  </p><p>谈起生和死，这些沉重的事物<br>下坠时曾变得轻盈<br>像是下陷的方糖<br>被你搅入暗色的街景  </p><p>路灯依次点照自己<br>缓慢燃烧惰性的寿命<br>大概你没有发现:每个夜晚<br>都有几只蛾落到了地上  </p><p>尸体们不会再起身<br>无可避免。一些声音产生<br>就取代着更幽暗的，杯底残留<br>的淤泥。我们已说无可说  </p><p align="right">2019-11<p><h3 id="通马桶"><a href="#通马桶" class="headerlink" title="通马桶"></a>通马桶</h3><p>寻常日子，我躺在卧室床上<br>想象你捅马桶的样子:  </p><p>热烈而焦急的汗水<br>用力的一捣<br>想要恢复生活本来的面目:  </p><p>沿逆时针慢跑，从环形操场南面<br>辗转到假草坪的中央<br>这样简单的快乐，我们总是乐此不疲  </p><p>但大部分时间，你忧虑<br>阴沉，一部分的你深入洗碗盆的底部<br>未剥皮的水果就这么燃烧着<br>许诺另一个日子，早晨和落日  </p><p>你还在等生活的小惊喜，<br>节日中的礼物、赐福<br>而坚硬的事物早已破碎<br>混入泥土的搅拌机中  </p><p>很快，那些细小的病菌就会将我们囊括<br>你捅。搅拌，尝试各种可能，然后洗手不干  </p><p align="right">2020-3<p><h3 id="回忆"><a href="#回忆" class="headerlink" title="回忆"></a>回忆</h3><p>她快十八岁时，黄昏<br>正从教室向北的三大块玻璃中褪去  </p><p>有人爱写她的名字，在雾中。取笑<br>4点半医院，吊瓶下读莫斯科日记的人  </p><p>当故事跋涉到1932年，在破碎的花鸟市场<br>他打开另一本小说，日记本隐藏断掉的线索:  </p><p>“像被钝器击中了肚子，我不知道她<br>是何时出生的，午夜还是子夜  </p><p>所以这一天都因为不确定而充满意义。”<br>晚自习漫长的像是监禁  </p><p>他站在迷宫的出口等待下课<br>好在散场后，送上未读完的礼物  </p><p align="right">2020-3<p><h3 id="另一种生活"><a href="#另一种生活" class="headerlink" title="另一种生活"></a>另一种生活</h3><p>像梯子一样，皮耶罗把身体镶嵌在一颗树下。<br>海岸线扁平的蓝色，海蟑螂聚集在琐碎的石头上<br>一个可有可无的树桩，纸屑和直尺遍布。<br>如果她举起手，从空无中取出一件工具<br>打造仅被名字和外表所修饰的物品<br>她也可以放牧自己，丢弃身体的疼痛。<br>海水拍打着孤岛，孤岛隐匿在下一封瓶中信中<br>对她而言时间就是永恒，迎接被流放的客人<br>为人们递出人原本的表情…  </p><p align="right">2020-3<p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>快速风格迁移网络学习</title>
      <link href="/2020/04/28/faststyle/"/>
      <url>/2020/04/28/faststyle/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;快速风格迁移网络由<a href="https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf" target="_blank" rel="noopener">《Perceptual Losses for Real-Time Style Transfer and Super-Resolution》</a>提出，其由生成网络和损失网络组成，如下图所示。  </p><a id="more"></a>  <p><img src="/images/faststyle1.jpg" alt="faststyle1"></p><center>快速风格迁移网络</center>  <p>&emsp;&emsp;原图片经过生成网络得到生成的风格图片后分别与目标图片和原图片计算两种损失。其中constant损失使生成图片与原图片整体相似，而风格损失则使生成的图片的风格向目标图片偏移。两种损失均为l2损失。图片的风格由Gram矩阵得到，Gram矩阵的计算公式为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Gram&#x3D;A^T·A</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;具体代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b,c,h,w &#x3D; input.size()</span><br><span class="line">F &#x3D; input.view(b,c,h*w)</span><br><span class="line">G &#x3D; torch.bmm(F,F.transpose(1,2))</span><br><span class="line">G.div_(h*w)</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;快速风格迁移效果如下图所示：<br><img src="/images/faststyle2.jpg" alt="faststyle1">  </p><center>实验效果</center>  <p>&emsp;&emsp;代码地址为<a href="https://github.com/talebolano/My-Pytorch-Learn--fast-style-Transfer" target="_blank" rel="noopener">My Pytorch-Learn fast style Transfer</a>。  </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>苹果</title>
      <link href="/2020/04/27/zhawen_2/"/>
      <url>/2020/04/27/zhawen_2/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;苹果还是绿的，然而草莓却已经变紫了。<br>&emsp;&emsp;现在我桌子上正好放了一个苹果，原来是六个，而现在是一个。才开始的时候，他们是放在塑料袋里的，红色和橙色，没有眼睛和嘴巴，虽然已过青春期但脸上正还残留着雀斑，是过度叛逆的痕迹。<br>&emsp;&emsp;也许继续这样下去，不动它们，没有任何打扰，它们会在一个春天的晚上慢慢地腐烂，让寝室充满它们衰老的臭味，让苍蝇和蛀虫蚀去它曾经变黑的身体而露出它坚韧而勇敢的愿望——五粒完好的种子。如果接下去还没有人去理睬它的愿望，那么这五粒种子说不定就会在我的桌子上发芽，长出叶子。而我则是传说里红盾家族的创始人，秉持着孵一颗鸡蛋成为百万富翁的白日梦，荷锄施肥。是的，我就是那个在宿舍里种有机苹果的绅士，在那个让拿破仑失落的夜晚，骗走了撒克逊女王的王冠。<br>&emsp;&emsp;但时光，或者说它们的现任耶和华——手持一卡通从楼下水果店走来的我——动手能力并没有我的脑洞一样壮阔，于是，它们都没有机会老去。一个刷完牙的早上，或者，一个毫无睡意的下午，像是正在寻求娱乐的杀人狂、正在偷盗礼物的顽童，挑选出最完美的一个，管他是智慧之果还是生命之果，现在最重要的是感官的愉悦和维C的补充，并在伊甸园里的野人——我的舍友们——发现之前，留下果核，那挑衅和虚无的核心。<br>&emsp;&emsp;一天两个的话，按我往常的习惯，这些苹果就会在三天中消失殆尽。但最后一个，不知道什么原因，我却始终没有动它。不是因为它的雀斑，因为每个苹果都有雀斑；不是因为它身上的虫洞，何况那里根本没有虫洞。也许是我想画静物了，我不会为了妓女而割掉自己的耳朵；也许一个苹果只是让我想起了白雪公主，哦，那位楼下卖水果的大婶脸色还算和蔼。我想起夏天在家里我吃下那些苹果，绿色而矮小，在盘子里等待着死亡的讯息。死亡是来自人类的大师。哦，多么完好的古拉格和奥兹维辛，但先生们，我并非在这里表达对我进食植物深深的忏悔，也并非对俄国人或是犹太人。我在想的只是颜色的变化究竟有什么不同，过去是绿色，而现在是橙色或者红色。我只是有一种潜在的怀念，不得不说，一颗苹果正设法将我带回旧时光里，尽管那并非什么有趣的峥嵘岁月，或许只是一个无聊的进食苹果的下午。而回忆是单一性的，指向朦胧，尽管今日不断的将你毁坏。<br>&emsp;&emsp;初中的校服送给了现在的初中生，而高中的校服颜色发黑，腐烂到现在。往日一个我曾暗恋的女中学生正提着装满蔬菜、肉食的菜篮远去，合着她渐渐的发胖的身体。你的情人还没有变紫，而月亮早已盈怀。世界从一开始就在毁坏你心中的美好，或者，像那群该死的物理学家说的一样，宇宙的熵总在无可挽回的增大，我们总在从有序走向混乱。而我早已为我自己备好了一副手铐，它可以防止我在冬天太寒冷的深夜出去咬人。<br>&emsp;&emsp;是的，你猜对了，苹果先生，初恋并非能从一颗苹果传递而来。过去只是我单纯的不想去咬你，而现在我想了，我不可能让你在我的桌子上腐烂的。向旧日子告别吧，我亲爱的苹果先生。  </p><p align="right">2014-12-30<p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>写于2014年的尾巴</title>
      <link href="/2020/04/27/zhawen_1/"/>
      <url>/2020/04/27/zhawen_1/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;二〇一四年最后一段和二〇一五年最开始的一段时间，我正坐在宿舍桌子的前面，打算看完那部评价不错的电影。<br>&emsp;&emsp;桌子上放着餐厅送的廉价杯子，里面是从隔壁宿舍借来的奶粉和勺子还没来得及冲洗干净，发出一种旧烂的气息。而笔记本里占据整个13寸屏幕的就是那部打算在年前看完的电影。<br>&emsp;&emsp;相比于去年，这真是糟糕透了。去年还跑去浙园放了一次孔明灯，而今年只剩下我待在宿舍里。尽管在屋子外面冷得够呛，但是说实在，呆在屋子里真的并不比屋子外面暖和多少。<br>&emsp;&emsp;手指快要在键盘上被冻麻了，并非偶尔响起的烟花和那声来自舍友的“我艹”让我的手指无意识的关掉播放器的全屏，在那个小小的灰蓝色边框里看见了时钟早已对齐它那走完漫长黑夜的指针，零点零刻。新年了，比一颗针的掉落还要安静。它就这样带走我的手指，点向继续播放的蓝色按钮，带走二〇一四。<br>&emsp;&emsp;那么我二〇一四年所确立的最后一个计划终于也失败了，本来是打算二〇一四年看完这部一九四六年的电影，然而现在到影片结束却还有四十多分钟，这部电影注定属于二〇一五年的前四十分钟。<br>&emsp;&emsp;非要在年前看完这部电影，对我来说，实际上并没有什么明确的意义。我大概只是空乏至此，像是一个虚无主义者，一个对经验上瘾但胆子微小的人，需要一种并非石英钟和电子闹钟的东西来指示我的时间，告诉我那大段的空白到底流失了什么，像是结绳记事，我的海马体并没有日程表那么可靠，它总是记不住相似的事情。<br>&emsp;&emsp;尽管零点已过，我还是不敢轻易的打开手机，打开网络连接，看看那些让我自暴自弃抑或羡慕的事情。联通公司的时间定义明显的与我们不同。他们把零点定在我们的三点或者四点，当下这个时间对于那些活在钱眼里的收费公司和计时员们来说还明确属于过去，而我们则明确的属于这样一个律法由他们订制的世界。好想打一个电话告诉10010不要每天一个短信的告知我话费余额不足。祝福你，那些我素昧平生的人，那些告知我规则的陌生人。<br>&emsp;&emsp;短暂的四十分钟，电影在新年的脚印里结束，还不错的经历，它让我在二〇一五年最开始的一段时间里落下了眼泪，这是从未拥有过的经验，它正驱走寒冷划出火柴的微热。<br>&emsp;&emsp;你依然要面朝食堂、火车风扇式的活下去，没有什么东西可以改变你，无论多黑暗和光明的事情。而外面的灯火早已熄灭，烟花只在零点那一刻响了仅仅一次，真的已经是另一年了，睡眠正在拥抱你，你身上的年轮和青苔又该增长一圈。时间之快，正如时代之慢。</p><p align="right">2015-01-01<p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>诗、桥与湖</title>
      <link href="/2020/02/13/my_poem_1/"/>
      <url>/2020/02/13/my_poem_1/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;这是我从怪物横行的星球上传递的最后的信息。我再也不愿浸淫于文学这肮脏的海洋。从此以后我将低调地写我的诗，找份工作糊口，再不打算出版我的作品了。</p><p align="right">——波拉尼奥<p><h1 id="犀湖（2013-2017）"><a href="#犀湖（2013-2017）" class="headerlink" title="犀湖（2013-2017）"></a>犀湖（2013-2017）</h1><h3 id="秋千"><a href="#秋千" class="headerlink" title="秋千"></a>秋千</h3><p>那里没有秋千，<br>我是指在我们的童年。  </p><p>所以，在黄金的年龄，这里<br>是煤渣的跑道，和尖锐的<br>铁皮滑梯，<br>我们腹部接触的<br>掉漆的单杠。  </p><p>之后，我们是不孤独的牧童<br>曾很轻易的向下<br>如此进入一条鱼的身体。<br>从一个名字到另一个<br>潮湿中溶化的<br>垃圾桶。鱼骨头，猫<br>正在叼去。  </p><p>迄今为止，我们仍会因为<br>一些小事改变。<br>比如说空气的质量和排座次序<br>而我，也会依然赦免你的呕吐——<br>你从没成为过鸽子，<br>你再没变成过甲虫。</p><p align="right">2014-3<p>  <a id="more"></a>    <h3 id="水底"><a href="#水底" class="headerlink" title="水底"></a>水底</h3><p>你想把窗帘拉上，<br>还没有到起风的时间。<br>太阳  是不能<br>被玄学和玻璃遮蔽。  </p><p>风扇在转，蛙声<br>快要晒成蝉鸣了。<br>还是没有风的声音。<br>影子依旧短小，像华尔兹<br>黑白里的卓别林。  </p><p>闹钟响着，已经下午一点一刻了，<br>她正起床，要去上学<br>和打扫卫生区。  </p><p>秋天的校服旧了许多，<br>正从青白变为紫色<br>黑色的墨点有些生硬。  </p><p>“要迟到了”<br>说这话时，突然有些宁静。<br>你还待在家里，<br>可乐需要加冰。  </p><p>电视依然在闪着，<br>有光的地方常常会让你忘了<br>卓别林发不出声音  </p><p align="right">2014-10<p>  <h3 id="在一个地铁车站"><a href="#在一个地铁车站" class="headerlink" title="在一个地铁车站"></a>在一个地铁车站</h3><p>夜已经深了，<br>你还在玻璃的另一面。  </p><p>这是无人知晓的时刻，<br>漆黑的容不下眼睛。<br>树枝过于脆弱，星光匍匐<br>像是罂粟和爱情。你喉间<br>的律法蔓延在大理石上。  </p><p>所以，你的牙齿有些变黄，<br>并不是回忆和时间的错。<br>吃一块硬玻璃，<br>让潮湿的花瓣不像你<br>让栏杆从远处合围过来<br>世界的原理正被电池驱动。  </p><p>可以掩盖石头和尴尬的空气么？<br>你进入时没有人在看你。<br>一个少女正在讲述美味的午饭<br>另一位正在迎接和驱赶：<br>列车已经可以到达龙泉驿。  </p><p>把你变苦，时间的叶子<br>酷似乌托邦的口香糖和哮喘病。  </p><p align="right">2014-11<p><h3 id="蒸汽"><a href="#蒸汽" class="headerlink" title="蒸汽"></a>蒸汽</h3><p>1773年，灰暗的苏格兰<br>旧世界的兔子，扑克和高跟鞋<br>老爵士的樱桃树<br>正落入你剪羊毛的手中。  </p><p>左边大西洋，右边是敦刻尔克<br>再向北一点，故事中冒险的海盗<br>跨越群岛的阴影上岸。  </p><p>更多黑牧师跨越未知的地形学<br>到达伯明翰的奴隶秤，还未习惯<br>新世界的革命练习<br>就要角斗和种玉米。  </p><p>你正读着加尔文和狄更斯，<br>（拿起黑伞的白手套）<br>把孤儿和皮肤不够细致的少女<br>送往没有出口的纺织厂<br>免遭人权启蒙和伦敦有毒的雾气  </p><p>最后一次忆起童年<br>谁会决心成为那个敲门的人<br>打碎六便士的许愿机<br>追赶溯回的鲑鱼？  </p><p>驱使煤炭行走的魔术师<br>和他吐出的蒸汽立下契约<br>像是完成撒克逊女王的一次飞吻<br>习惯逐渐专横的巴洛克<br>他在愤怒的下午发明的管风乐<br>石中剑和波西米亚的小提琴  </p><p align="right">2014-12<p><h3 id="洛丽塔"><a href="#洛丽塔" class="headerlink" title="洛丽塔"></a>洛丽塔</h3><p>快要黄昏了，你的心<br>因为白天的结束而变得疲惫。<br>雨水落在行道树上，以致<br>车玻璃也有些忧郁。  </p><p>“浸了水的枪口是蓝色的”<br>你告诉我。我曾前往的那个夜晚，<br>暴风雪里关闭的阁楼，阀门旋转着<br>万花筒，无法再继续。  </p><p>细小的脸颊破碎之后，你的双手<br>压出一块灰色的蛋糕，<br>落叶往更深的海里沉着，<br>猎人们正将火药捣乱。  </p><p>“我也许可以教你游泳”<br>时针的不安里有着睡眠的寒冷。<br>你所凝视过的答案，剩下的<br>只有火所熄灭的戏剧。  </p><p>你又一次的哭了起来，像是<br>难以愈合的伤口。数次逃走的<br>夜晚，就这样悄然无声的落了下来。  </p><p align="right">2015-3<p><h3 id="归来的旅程"><a href="#归来的旅程" class="headerlink" title="归来的旅程"></a>归来的旅程</h3><p>收拾完行李之后，我们坐在桌子前<br>打开手机。下午的阳光照在阳台的<br>栏杆，那些我没来得及收起来的<br>袜子上。而你抽着烟，灰色在半空消散。<br>成都依然有些寒冷，就像，你的红领巾<br>有些破旧，它在，你脖子上已有廿年的时间。<br>黑色，另一些是灰的，像是有人穿过的马路<br>那些我们走过时醒来的老路。<br>二十年，我早已失去相信你的力量，<br>搬到了桥上，喝啤酒。惧怕陌生的电话<br>拒绝凝视中蔓延的雾气。一动不动的等待<br>绿灯和医生的判词。你已经不能说起往事。<br>剩下的时间里，我们去吃晚餐。<br>用勺子分开蛋包饭，像是梦里一直做得那样<br>那个没有脸的女人你一点都不陌生。  </p><p align="right">2015-3<p><h3 id="无法说明的事"><a href="#无法说明的事" class="headerlink" title="无法说明的事"></a>无法说明的事</h3><p>你，会拆柴油机么？会讲笑话么？<br>我听到，你的口袋里硬币的声音。<br>那边，中学的小卖部，冰糕<br>并不好吃，尤其是没有榛果的那种。<br>在夏天，你要适应那些<br>比你更凉的东西。  </p><p>所以，先学会用一只腿走路吧<br>街道里满载着叶子和潮湿的方言。<br>要小心跌倒，小心食人鱼<br>咀嚼每一个陌生的名字。<br>你要请他们喝啤酒，穿上<br>潜水衣，窥测在他们<br>心底寄居的螃蟹。  </p><p>回去的时候，要记得拉下卷帘门，<br>计程车最好来双份，不要辣椒。<br>深夜里酒吧拥挤，一把吉他风流，<br>而你只会吹口琴，并非他们说的<br>三好学生。若是想要姑娘，<br>就要学得主动，换上鲜亮的衣服<br>和理想，用一生去欺骗她，带上她<br>穿过卧室和餐厅。  </p><p>不要再尝试定格空中的鸽群了，你<br>要做的只是，拿起锤子和扳手，<br>一点点的向下，深入酒精，像是<br>深入一个过于空旷的秘密<br>有时候需要火花，而更多的夜晚<br>只要你支起耳朵。<br>听听水声，击打在碗筷上<br>并喜欢上，那些无害的花儿。  </p><p align="right">2015-3<p><h3 id="多肉植物"><a href="#多肉植物" class="headerlink" title="多肉植物"></a>多肉植物</h3><p>梧桐要高于柳树了，此刻，<br>已不是银杏发苦的季节。<br>早上6点，我都会被飞机的爆破音<br>过早的唤醒，刷牙，咀嚼窗外的鸟声。<br>（他们储存着脂肪，正准备远离我们的眼睛）<br>道旁的大叶樟无疑是比不上香樟<br>让人熟悉，我还是记住了<br>他的名字。（偶然抑或故意？）<br>因为玫瑰和鸢尾的一场战争，樱桃和樱花<br>让人无法分清，死者和鼻血的距离。<br>我早已双修了植物学，懂得如何发酵野草<br>和蘑菇，认养一只没有父母的火萤。<br>而你，远离地面十米的绿色花朵，独自待在阳台上<br>君临细小的国土和王冠，正与厕所为邻，日复一日的<br>沉默不语。（想浇水？求我呢，是医生让我这么做的）<br>因为新闻署的一纸敕令，你拒绝<br>成为我的山鬼，或者二次元少女。  </p><p align="right">2015-4<p><h3 id="生活……"><a href="#生活……" class="headerlink" title="生活……"></a>生活……</h3><p>白色，是越来越少了<br>吸管下的牛奶盒<br>发出扭曲的声音  </p><p>你的笔尖在冷却，整个下午<br>把盒子揉成一团，看着<br>墙壁上的光线变斜变旧<br>躺在卧室的床上，<br>便不想出去。   </p><p>电视在门外低语。<br>更多破碎的细节<br>是午睡时不自主的呼气。<br>温度和灰尘都在下降，<br>你开始下坠，沿着楼道<br>绽开的裂痕。墙纸剥落的窸窣，<br>正要进入你的身体。  </p><p>像是完成一场童年的魂斗罗，<br>你拔下连接电视的手柄<br>起身遥望窗外：<br>一条发灰的河堤，褪色中的桥梁，<br>蝉在衰弱里越来越小的噪音。  </p><p>作业，已写不下去…… </p><p align="right">2015-5<p><h3 id="棋盘的写生练习"><a href="#棋盘的写生练习" class="headerlink" title="棋盘的写生练习"></a>棋盘的写生练习</h3><p>头戴黑礼帽的吉伦特对位<br>夜晚的重量，继续增多<br>从黄昏开始，你所能<br>触到的白色就越来越少<br>被悬空的酒杯都在远离舞会<br>降落在别处的人生。  </p><p>那么“重开一盘吧”<br>让钟声倒退，入殓的<br>王国在锦砖上复活<br>云母的反侧，从新生代回到泥盆纪<br>路易的颈椎长出新肉  </p><p>但对面的人面带笑意，依次翻动<br>过时的阴谋。一手好牌所剩无几<br>探戈骑士，被对位雨格诺代替<br>“猴取僧正”，革命在雨里<br>低声呼喊着雅各宾<br>缺少长袜的少女逼近底线  </p><p>要逃么？并联如绳的编织头发<br>床单坠向地下一层。跳出窗外<br>和宫闱秘史。唯有骑枪<br>把你顶回原处，黑和白的地板<br>出现了红。 </p><p>“将”他终于学会了用中文<br>翻译这个词，安抚督政府<br>从葡萄跳到浓雾<br>历史学绝不反悔，端来白米饭<br>第二次被审判的人，第二次被断头  </p><p align="right">2015-6<p><h3 id="在夏天，想起往事"><a href="#在夏天，想起往事" class="headerlink" title="在夏天，想起往事"></a>在夏天，想起往事</h3><p>风，更多的风声<br>挤过下午的树林，和<br>并不算大的草地，留下<br>它转瞬即逝的阴影  </p><p>这个夏天，你第一次<br>注意到蝉声的躁动<br>过于透明的天空折射<br>昨晚的那场雨<br>和水泥上淡蓝的积水<br>小时候你所畏惧的湖泊<br>也在变的安静  </p><p>花猫依然很怕你<br>此刻穿过寂寥街道的它<br>是否就是蹭过你鞋的那一只<br>已无人知晓。树下<br>散落太多的光斑<br>变的模糊。午睡在初中教室<br>难的老师一次温和的脾气  </p><p>洛，这个夏天的烈日<br>必将因你<br>而被往事遮蔽<br>洛，我在这个夏天所想起的往事<br>还不能过早告诉你  </p><p align="right">2015-6<p>  <h3 id="去往深海，治疗减压病"><a href="#去往深海，治疗减压病" class="headerlink" title="去往深海，治疗减压病"></a>去往深海，治疗减压病</h3><p>黑色，逐渐变浓的黑色<br>撕下幕布上多余的日历<br>衰老的光从眼中发出：<br>一艘废旧游轮抛锚的声音。  </p><p>海岸线仍在上涨，远处<br>浮起待售的岛屿。年复一年<br>鱼眼早已习惯各种透明的波纹<br>委身于我们脱下的修辞<br>所带来的渴意。被海怪点亮的众人，冷汗<br>伸出更多的鮟鱇鱼。  </p><p>每年的夏季或者更晚，<br>我们都从一个更小的车站出发<br>到达下一片瘦骨嶙峋的海洋，与<br>涉水而来的友人们握手言和<br>吐露自身，再次陷入<br>久未愈合的秘密。  </p><p>现在，穿上防水衣<br>睡眠更少的色彩<br>去往台下，治疗减压病  </p><p align="right">2015-8<p><h3 id="雨中的陌生人"><a href="#雨中的陌生人" class="headerlink" title="雨中的陌生人"></a>雨中的陌生人</h3><p>他，自雨天巡演归来<br>有时小跑，有时犹豫<br>伴随鱼群旋转向上的汽笛  </p><p>隔着雨幕，隔着更多被猜测的旅途<br>和十步一顿的楼梯。时常卷入镜头的路人<br>把持破旧的宿舍楼，叙事裹挟<br>这行进过半的剧情  </p><p>在一个更旧的故事中<br>他已一个人返回寝室<br>平静在台灯的海岸下，左手<br>一如既往步入过期新闻，无限的电路<br>检阅彩色和灰色的人像<br>盲目怀念起往事  </p><p>“秋天过后，我们这里开始整夜下雨。”<br>他费力完成台词，熄灭植物的火<br>伧促上场的女主角转身回到脑外<br>电话不会响，且需要更多生产眼泪的情节<br>才能回应搁浅的观众席  </p><p>于是他望向窗外，退回独白的内部<br>可以多残酷呢，更深的衰老<br>当秋雨伴随着逐渐轰鸣的割草机  </p><p align="right">2015-9<p><h3 id="病人"><a href="#病人" class="headerlink" title="病人"></a>病人</h3><p>雨水击打着午后的病床，时间也日渐发脆<br>九月，倒映在静脉里<br>沉默渗出稀释的盐。  </p><p>手背上多出的小孔，并非出于敌意。<br>他圈养麻雀，在小诊所的输液室<br>刺透的疼痛是预料之中的剧情<br>又像是另一个早已结束故事的回音。  </p><p>无论是白色合拢的房间，上升的<br>体温计与高三物理<br>她的眼神已不再让人恐惧。一整天<br>他都显得轻松、懒散。<br>没有事再能消耗他的心   </p><p>衰老的母亲也终于<br>接受被忽略多时的真相<br>——他还没变老，就已开始生病  </p><p align="right">2015-11<p><h3 id="阵雨"><a href="#阵雨" class="headerlink" title="阵雨"></a>阵雨</h3><p>一阵突然的雨冷却来早的春天<br>在没有人告别的街道<br>自行车的航迹在水洼处并轨<br>翻动色浅的砖块  </p><p>几把雨伞颓然阻挡雨势<br>水滴就很快结束自身的透白<br>更远处的路人，蝉翼般蜕行<br>辗转于食堂和热水房<br>小心地踩过世界的表面  </p><p>争吵，大喊，百无聊赖<br>悬浮于半空，不断地路过<br>自身的正午。打开褪色的抽屉，<br>躲避趋近的真相。  </p><p>继续睡眠，继续不合时宜<br>的停下。回到时间之外的床上<br>喝海水，喝一切失效的预言  </p><p align="right">2016-3<p><h3 id="春分"><a href="#春分" class="headerlink" title="春分"></a>春分</h3><p>每当鸟儿起飞，一些影子就会腾空<br>从地面跳跃到另一些阴影上。<br>我走在路上。不知名的鸟类变多了<br>树木也持续抽枝<br>延伸季节应有的形状。  </p><p>改变似乎总在生活之外发生<br>又时常背弃自己的选择。<br>多余的风携带变质的嗓音<br>微小的雨滴不断凝聚<br>感染街道易朽的鼻子，像是<br>春天所欠入冬的一次重度感冒。  </p><p>而我也时常停住，感受高压线上<br>鸟群的危险。和空阔中<br>失去重量的云层。更多的叶子脱落<br>在这个变冷的雨天。更多的窥测<br>止步于她的心声。  </p><p align="right">2016-3<p><h3 id="花朵的公式"><a href="#花朵的公式" class="headerlink" title="花朵的公式"></a>花朵的公式</h3><p>雨很快就停了，受潮的云层开始放晴<br>窗外清晰的蝉声，一段聒噪的前奏<br>被鸟类捕获，变得时断时续  </p><p>午休在远离床板，他也起身穿鞋<br>偶尔望向楼下的行人，那只跳上长椅的猫<br>和远处响起的篮球。四月的身影<br>缩在受冷的脚下，无法横渡<br>眼前多变的水域  </p><p>“仙人的手臂也会多刺而易碎？”<br>如果是我，那一定还是<br>在为窗台上一株莫名歪生的多肉而苦恼<br>那盆栽的盲人，接触塑料的边界<br>拒绝悬空的园丁。  </p><p>像是一朵无法放开的花，凝视着，告别<br>柳絮破碎的暮春。你在夏天之前<br>变得愈发孤独，而不再依靠危险的爱<br>去对抗下午，连同夜晚的来临  </p><p align="right">2016-4<p><h3 id="七月……"><a href="#七月……" class="headerlink" title="七月……"></a>七月……</h3><p>七月已去，并没有连绵的雨天<br>蝉褪去它仅剩的壳<br>虫鸣，干扰英语书上入眠的午后<br>干扰你过度损耗的听力  </p><p>窗外，迷彩的施工队和水泥车<br>已开始填充草坪的中心。<br>你生锈的胃也被缓慢搅痛<br>午饭重回身体的温度，梦境深处<br>潮湿粘连米粒  </p><p>再不会有割草机从我们头顶驶过了<br>置身事外，夏天独自发育，肿胀<br>遵循陈旧的预言。你<br>却一再滑落旧日记的湖心<br>寻找一种落水的姿势  </p><p>坠入幻觉的泳池<br>生活，它周转自如的阴影  </p><p align="right">2016-3<p>  <h3 id="老街区"><a href="#老街区" class="headerlink" title="老街区"></a>老街区</h3><p>他们之中有几个秃头、许多胖子<br>缺少高个和没结扎过的女人。在年轻的时候<br>他们也都年轻过。多巴胺和夏夜<br>使他们都曾渴望过一条裙子，或者不止一条<br>渴望权力，热衷于八角帽<br>和来自假象敌的血，使用红色虚构的口号。<br>他们偶尔激烈而时常乏味<br>更多的场合，他们是生活<br>是群架中不起眼的部分<br>站在革命广场外的草坪上，一群虚胖的混混<br>肆意击打衰变的猫，在概率论里<br>起飞，裹挟周身的泥泞:绝大部分人<br>就这样消失在迎面而来的水中。<br>而今，你所能看到的他们并不是极地馆的海豚<br>来自幸存者的峡湾。种种衰老<br>使这些中年人近似长久未洗的袜子<br>泡在水盆，拥有淤泥的味道。<br>却依旧习惯<br>把时间消磨在激情中：每晚在路边聚会<br>成为弥漫不去的麻将、马扎，成为白色的噪音<br>赌钱，一块两块，他们不敢拿出更多，不敢<br>再转身，抵达铁栏杆的对面<br>直面快车道曲折爬动的灯火<br>直面眼泪<br>无声而恶意的揣测。  </p><p align="right">2016-4<p>  <h3 id="聚会夜"><a href="#聚会夜" class="headerlink" title="聚会夜"></a>聚会夜</h3><p>又一晚，我们错过了熄灯<br>错过了宿舍楼，和树叶的集体失声。<br>在室外，用一根干枯吸管吮吸<br>头顶暗红的湖泊。  </p><p>割草机已陷入沉默，草坪里<br>满布呕吐，一些新鲜的豆腐脑。醉酒的人<br>选择唱与黄色笑话，不相衬的职业，旅游。<br>陷阱几经婉转，不断走向歧路<br>再谈，就要咬痛伤口。  </p><p>“越来越多的我正被在失去<br>所有漫长的瞬间”<br>短暂的颤抖，酒气搅动新生的黑<br>我们不再说起往事和眼前的洗衣店<br>那些疯狂的蓝<br>月亮曾濯洗我们褪色的床单  </p><p>两点过后，烧烤摊终于逃出自夸<br>虚构的图纸。你用一把旧钥匙<br>打开厕所的拉链，打开滑落泥泞的身体<br>还未使用，你已无法提起海绵体<br>射出无愧于年纪的水枪。  </p><p align="right">2016-5<p><h3 id="高中"><a href="#高中" class="headerlink" title="高中"></a>高中</h3><p>下坠，如此轻盈的剥落<br>和剥落感。水花四起  </p><p>整整一天，夏日溺亡<br>浮在铃声的焦虑中  </p><p>上百个午后，抄写作业<br>学漫画口气，移向走廊的小群体  </p><p>一个暗黄的声音，低沉<br>显影在教室的门口，沉下水底  </p><p>他说，关窗吧<br>风扇已不能阻隔热气的无力  </p><p align="right">2016-5<p><h3 id="南湖公园"><a href="#南湖公园" class="headerlink" title="南湖公园"></a>南湖公园</h3><h3 id="emsp-emsp-——忆与王尧同游南湖公园"><a href="#emsp-emsp-——忆与王尧同游南湖公园" class="headerlink" title="&emsp;&emsp;——忆与王尧同游南湖公园"></a>&emsp;&emsp;——忆与王尧同游南湖公园</h3><p>它无法封冻你的回忆，在深冬<br>泮河的暖流划过脏冰堆积的岸<br>占据狭窄湖心的舞台。沿小镇陌生化<br>用老年的余温跳一跳，跳交际舞  </p><p>曾是臭水洼的拆迁房在不远处<br>见证手势，灰中山遗留的弯路。<br>但农民工正迁徙，拥挤在向北的十字路<br>赶往长途汽车站或是火车站<br>疲倦于历史未卜的前程  </p><p>在那些你记忆的夜晚，它也只是公园<br>衰老而平庸。白鹅形状的飞船从不会起飞<br>即使游人一再被铁胃吞没<br>驱使费力的脚蹼滑行，也难以亲近<br>水底生锈的那年秋  </p><p>而今，湖水日益干枯，赤裸众多烂尾楼<br>它已无法中止纪念的手掌，搁浅<br>在纸片泡沫的抒情体里，徒劳撞向深水区<br>那些窥探着我们，永远隐没微光的石头  </p><p align="right">2016-5<p><h3 id="青年路"><a href="#青年路" class="headerlink" title="青年路"></a>青年路</h3><p>街道深埋入粉色积雪:一道青春期的裂隙<br>阴影，或许是路边树，界线填充出米色细枝<br>低下头，它是现实狭隘的水泥桥<br>正沿旅游手册曲折展开  </p><p>暗红的公交线串联起细节:新华书店，聋哑<br>小贩，青州城与拉面馆。除非被倒置<br>泮河永远向下，持续坠入公园的冷色调<br>更多善忘的店铺占据雪地广阔的几厘米<br>建筑保持沉没姿态，压住地图也封冻浑浊的方言。  </p><p>此外，它已无其他有趣的回忆<br>为海马标注。深冬的老人或将继续奔跑，挥霍<br>旧时代的热气。陌生的青年<br>也会怀抱一册新语录，在校门口步入拘谨的慢   </p><p>而你，往事如织的游人，因复杂的传言疲倦<br>他和她都渐无联络，丢失音信。像是你的标题下<br>仍写满各种地址，如今也不再与你发生关联  </p><p align="right">2016-5<p><h3 id="明信片"><a href="#明信片" class="headerlink" title="明信片"></a>明信片</h3><p>从水声淹没处看去:池中狮头、<br>静止翻滚的水，在台灯的默许下<br>正构成等高线幽深的一角  </p><p>儿童，少先队员，拉手风琴的共青团员<br>环居其上，他们随意在石栏和假山的边沿<br>将年轻的面具滞留于此刻的轻松  </p><p>现在，离她最近的人也正离池心最近，食指<br>向下。她的目光已刺透危险，迟疑<br>表情越过失焦的瞬间。衰老  </p><p>抵达对视的脸上:一小串烟花响起<br>汽车轻声的惊叫，徒生疲倦。永不消散<br>缄默的独白在她门外徘徊  </p><p align="right">2016-10<p><h3 id="生活……-1"><a href="#生活……-1" class="headerlink" title="生活……"></a>生活……</h3><p>他们骑车横渡周末……<br>他半路折回，想起锁和钥匙<br>穿过丘陵和市区层层的浓雾  </p><p>人们过桥时，他正从某个狭窄市场<br>抄一条并不近的近路。从菜叶到<br>鱼鳞，死鱼眼。猪肉的红与白……  </p><p>或许所有人都已尽力配合<br>但他还是放弃了。你没来<br>真是可惜。事后，他们总这样说  </p><p>或许几分钟后，他会回到室内，锁上门<br>并进入失效的视觉。迟滞的黑暗<br>多少会让他安心  </p><p align="right">2016-10<p><h3 id="镜子"><a href="#镜子" class="headerlink" title="镜子"></a>镜子</h3><p>从结局归来，她焚烧<br>一扇旧窗子。触抵时间的雾  </p><p>我们的雨，我们隐匿的<br>对话，如钟声悬浮。火花<br>搁于记忆孵卵的浅层  </p><p>她，拨动镜面和湿头发<br>摇晃我们的老房子，让风熄灭<br>裸露它们不洁的曲变  </p><p>透过衰老、引力和湖水，我们<br>再次回到彼此窥视的深渊，想起<br>各自丢失的罐子。  </p><p>童年在冰上，笑。她玻璃的牛奶<br>洒落，那些银色波纹<br>正漫过回声环绕的废墟  </p><p align="right">2016-10<p><h3 id="图书馆小练习"><a href="#图书馆小练习" class="headerlink" title="图书馆小练习"></a>图书馆小练习</h3><p>鸟雀是否包容了她<br>所有缺失姓名的快乐<br>她所怀抱的湖水，<br>长过裙裾<br>和无法愈合的疾病。  </p><p>而雨水哑火远离植物的忧郁，甜<br>跃向轻盈的舌尖。陌生的单词<br>掉落在玻璃上，天花板上<br>变得口齿不清  </p><p>那时，被打破的究竟是什么<br>盐罐或者，永远也不是<br>所有的海下沉到他的记忆<br>再次进入的大街依然绝望、肮脏  </p><p>身着黑衣的黑猫<br>转身<br>返回打湿自己的那场雨<br>孵化记忆的贝壳，它有时<br>却不能收获一颗沙粒  </p><p align="right">2016-10<p><h3 id="帕拉杰诺夫的碎片"><a href="#帕拉杰诺夫的碎片" class="headerlink" title="帕拉杰诺夫的碎片"></a>帕拉杰诺夫的碎片</h3><p>门前，熟悉的老虎还在青铜里练习<br>跳水、一个女人的历史剧。众多残肢<br>将她扮演:愿望吃人，也吐出绝望的果核<br>很快，时间的士兵将从海底游回<br>数落离场的演员:你们用花瓣替换黄金<br>过于童年的错误<br>但玫瑰并非总指向深渊。但日期<br>她说，死于厌倦而非失落  </p><p align="right">2016-11<p><h3 id="霉斑"><a href="#霉斑" class="headerlink" title="霉斑"></a>霉斑</h3><p>挑选时的凝视<br>也发生在开口前、遗弃前  </p><p>这小块的生活业已坍缩，对众人展示<br>她可见的厌烦、绝望……  </p><p>我并非没有什么好期待的<br>而衰落远比婴儿要美  </p><p>但脚气久了，全身也会变烂  </p><p>他看着客厅平静的脸，时间在飞渡<br>大概会在电梯前和解  </p><p>跳过这一个，我们继续<br>剥剩下的栗子，咽下午后<br>琐碎的病理  </p><p align="right">2016-11<p>  <h3 id="致曹文康及其他友人"><a href="#致曹文康及其他友人" class="headerlink" title="致曹文康及其他友人"></a>致曹文康及其他友人</h3><p>出租车胁来三个人，终日<br>在冰面上滑行的三个<br>抵达幻觉的海湾，距离感<br>散发细微的空隙  </p><p>几种甜包围他们<br>沉默下坠的雾，此刻<br>相互打探自己<br>不再透明的面具<br>——那成年的海岸线<br>那相框肋骨的纹理  </p><p>一切向后裂开，甚至<br>没费太多功夫的笑<br>回忆，他们很快<br>就回到了三年前，回到<br>误会中，并不热烈的午后:  </p><p>人群一而再的错失，罔顾<br>四周，每一次开口<br>都更显陈旧。弄脏雪地的人<br>在回转处放慢钟摆的频率  </p><p align="right">2016-11<p>  <h3 id="剩下的，让水来说……"><a href="#剩下的，让水来说……" class="headerlink" title="剩下的，让水来说……"></a>剩下的，让水来说……</h3><p>从上面看，它们浑如圆、椭球<br>严厉线条的交汇。侧面是<br>背面，也是细致的砖缝。<br>白色酸蚀着纸<br>并不紧致的边界，模糊<br>乃至不洁的突出  </p><p>甚至可以一眼进到它的核里<br>在随处的结构，辨识结石<br>细小的形心、镜像破碎的手臂<br>它们终生止于纠缠，不休的贯穿<br>每一处都是牙齿<br>咀嚼着舌头……  </p><p align="right">2016-11<p><h3 id="游记一则"><a href="#游记一则" class="headerlink" title="游记一则"></a>游记一则</h3><h3 id="emsp-emsp-——忆与王尧游烈士墓地"><a href="#emsp-emsp-——忆与王尧游烈士墓地" class="headerlink" title="&emsp;&emsp;——忆与王尧游烈士墓地"></a>&emsp;&emsp;——忆与王尧游烈士墓地</h3><p>五年前，他们越过城市中心<br>严肃的烈士陵园<br>到达后面漆黑的小山包。<br>山顶是安全的乱坟，没死光的蚊虫<br>发出细微的欢迎、旋转<br>围绕单薄的手臂。候鸟早已消尽<br>星系们正坠入秋末、巨大的光污染<br>的手中。对面暗红的湖泊<br>人群隐匿在建筑后，密语<br>止于寒冷、易朽的剧情  </p><p>他们再见面大约是夏末<br>在某个时刻之后<br>消失在深水中，跟随鱼群<br>大多数话题已不可挽回，缄默如暧昧<br>他们记不得为什么要到这，之后<br>又该去向哪里  </p><p align="right">2016-12<p><h3 id="写于去年六月"><a href="#写于去年六月" class="headerlink" title="写于去年六月"></a>写于去年六月</h3><h3 id="emsp-emsp-——给所有没成为朋友的朋友"><a href="#emsp-emsp-——给所有没成为朋友的朋友" class="headerlink" title="&emsp;&emsp;——给所有没成为朋友的朋友"></a>&emsp;&emsp;——给所有没成为朋友的朋友</h3><p>第一年元旦，他们相聚在湖边<br>艺术馆后大片潮湿的脏草地上，拿着<br>低矮的桌子、纸杯。湖面还没有结冰<br>夜雾暗红，浸入短小的灌木。<br>喧闹无疑是冷的，游戏也是<br>没有人肯把手臂抽出，喝冻硬的可乐。<br>人声稀疏，在相似的人脸里升温<br>像是寒酸的婚礼、简促排练的年会。<br>零点过后，大部分人就消失了<br>他们坚持放完灯再走<br>此后几年，他们没再见过。也没人提起<br>此刻围成的并不紧凑的圆形。堕入回忆<br>的人也停下，站在相似的小湖——六月<br>雨水不能，递回……一个湿冷的肺部  </p><p align="right">2017-4<p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/02/12/hello-world/"/>
      <url>/2020/02/12/hello-world/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello world! github pages.</span><br></pre></td></tr></table></figure><p>测试图片</p><p><img src="https://raw.githubusercontent.com/talebolano/TensorRT-Yolov3/master/image/example.png" alt="图片alt"></p><p>测试流程图</p><div id="flowchart-0" class="flow-chart"></div><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Startop=>operation: Your Operationcond=>condition: Yes or No?e=>endst->op->condcond(yes)->econd(no)->op</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
